{"ast":null,"code":"// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nexport class SynthesisContext {\n  constructor(speechSynthesizer) {\n    this.privContext = {};\n    this.privSpeechSynthesizer = speechSynthesizer;\n  }\n  /**\n   * Adds a section to the synthesis.context object.\n   * @param sectionName Name of the section to add.\n   * @param value JSON serializable object that represents the value.\n   */\n\n\n  setSection(sectionName, value) {\n    this.privContext[sectionName] = value;\n  }\n  /**\n   * Sets the audio output format for synthesis context generation.\n   * @param format {AudioOutputFormatImpl} the output format\n   */\n\n\n  set audioOutputFormat(format) {\n    this.privAudioOutputFormat = format;\n  }\n\n  toJSON() {\n    const synthesisSection = this.buildSynthesisContext();\n    this.setSection(\"synthesis\", synthesisSection);\n    return JSON.stringify(this.privContext);\n  }\n\n  buildSynthesisContext() {\n    return {\n      audio: {\n        metadataOptions: {\n          sentenceBoundaryEnabled: false,\n          wordBoundaryEnabled: !!this.privSpeechSynthesizer.wordBoundary\n        },\n        outputFormat: this.privAudioOutputFormat.requestAudioFormatString\n      },\n      language: {\n        autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n      }\n    };\n  }\n\n}","map":{"version":3,"sources":["src/common.speech/SynthesisContext.ts"],"names":[],"mappings":"AAAA;AACA;;AAKA;;;AAGG;AACH,OAAM,MAAO,gBAAP,CAAuB;AAKzB,EAAA,WAAA,CAAY,iBAAZ,EAAgD;AAJxC,SAAA,WAAA,GAA0C,EAA1C;AAKJ,SAAK,qBAAL,GAA6B,iBAA7B;AACH;AAED;;;;AAIG;;;AACI,EAAA,UAAU,CAAC,WAAD,EAAsB,KAAtB,EAAgC;AAC7C,SAAK,WAAL,CAAiB,WAAjB,IAAgC,KAAhC;AACH;AAED;;;AAGG;;;AACH,MAAW,iBAAX,CAA6B,MAA7B,EAA0D;AACtD,SAAK,qBAAL,GAA6B,MAA7B;AACH;;AAEM,EAAA,MAAM,GAAA;AAET,UAAM,gBAAgB,GAAsB,KAAK,qBAAL,EAA5C;AACA,SAAK,UAAL,CAAgB,WAAhB,EAA6B,gBAA7B;AAEA,WAAO,IAAI,CAAC,SAAL,CAAe,KAAK,WAApB,CAAP;AACH;;AAEO,EAAA,qBAAqB,GAAA;AACzB,WAAO;AACH,MAAA,KAAK,EAAE;AACH,QAAA,eAAe,EAAE;AACb,UAAA,uBAAuB,EAAE,KADZ;AAEb,UAAA,mBAAmB,EAAG,CAAC,CAAC,KAAK,qBAAL,CAA2B;AAFtC,SADd;AAKH,QAAA,YAAY,EAAE,KAAK,qBAAL,CAA2B;AALtC,OADJ;AAQH,MAAA,QAAQ,EAAE;AACN,QAAA,aAAa,EAAE,KAAK,qBAAL,CAA2B;AADpC;AARP,KAAP;AAYH;;AA/CwB","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat\";\r\nimport { PropertyId, SpeechSynthesizer } from \"../sdk/Exports\";\r\n\r\n/**\r\n * Represents the JSON used in the synthesis.context message sent to the speech service.\r\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\r\n */\r\nexport class SynthesisContext {\r\n    private privContext: { [section: string]: any } = {};\r\n    private privSpeechSynthesizer: SpeechSynthesizer;\r\n    private privAudioOutputFormat: AudioOutputFormatImpl;\r\n\r\n    constructor(speechSynthesizer: SpeechSynthesizer) {\r\n        this.privSpeechSynthesizer = speechSynthesizer;\r\n    }\r\n\r\n    /**\r\n     * Adds a section to the synthesis.context object.\r\n     * @param sectionName Name of the section to add.\r\n     * @param value JSON serializable object that represents the value.\r\n     */\r\n    public setSection(sectionName: string, value: any): void {\r\n        this.privContext[sectionName] = value;\r\n    }\r\n\r\n    /**\r\n     * Sets the audio output format for synthesis context generation.\r\n     * @param format {AudioOutputFormatImpl} the output format\r\n     */\r\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\r\n        this.privAudioOutputFormat = format;\r\n    }\r\n\r\n    public toJSON(): string {\r\n\r\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext();\r\n        this.setSection(\"synthesis\", synthesisSection);\r\n\r\n        return JSON.stringify(this.privContext);\r\n    }\r\n\r\n    private buildSynthesisContext(): ISynthesisSection {\r\n        return {\r\n            audio: {\r\n                metadataOptions: {\r\n                    sentenceBoundaryEnabled: false,\r\n                    wordBoundaryEnabled: (!!this.privSpeechSynthesizer.wordBoundary),\r\n                },\r\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\r\n            },\r\n            language: {\r\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\r\n            }\r\n        };\r\n    }\r\n}\r\n\r\ninterface ISynthesisSection {\r\n    audio: {\r\n        outputFormat: string,\r\n        metadataOptions: {\r\n            wordBoundaryEnabled: boolean,\r\n            sentenceBoundaryEnabled: boolean,\r\n        }\r\n    };\r\n    language: {\r\n        autoDetection: boolean\r\n    };\r\n}\r\n"]},"metadata":{},"sourceType":"module"}